dataset_config:
  dataset: st_dataset
  file: examples/st_covost2/dataset/st_dataset.py:get_speech_dataset
  train_data_path: /mgData2/yxdu/m2m-70/SLAM-LLM/../../data/fleurs_all/data/mix_train_covost2_fleurs.jsonl
  val_data_path: /mgData2/yxdu/m2m-70/SLAM-LLM/../../data/fleurs_all/data/srt_test_10.jsonl
  input_type: mel
  mel_size: 128
  fix_length_audio: 30
  source: 2828
  mode: srt
  validnum: -2
train_config:
  enable_fsdp: false
  enable_ddp: true
  validation_interval: 2000
  use_peft: false
  model_name: asr
  num_epochs: 10
  freeze_encoder: true
  freeze_llm: true
  batching_strategy: custom
  gradient_accumulation_steps: 1
  warmup_steps: 1000
  total_steps: 200000
  lr: 0.0001
  batch_size_training: 8
  val_batch_size: 8
  num_workers_dataloader: 16
  output_dir: /mgData2/yxdu/m2m-70/SLAM-LLM/output/taslp-no-balance-2
  use_fp16: false
  use_fast_kernels: false
fsdp_config:
  pure_bf16: true
log_config:
  use_wandb: true
  wandb_project_name: fleur
  wandb_exp_name: srt
model_config:
  llm_name: GemmaX2-28-9B-v0.1
  llm_path: /mgData2/yxdu/m2m-70/SLAM-LLM/../models/GemmaX2-28-9B-v0.1
  llm_dim: 3584
  encoder_name: whisper
  encoder_projector_ds_rate: 5
  encoder_path: ''
  encoder_path_hf: /mgData2/yxdu/m2m-70/SLAM-LLM/../models/whisper-large-v3
  encoder_dim: 1280
  encoder_projector: qqm
  query_len: 150
metric: acc
ckpt_path: /mgData2/yxdu/m2m-70/SLAM-LLM/output/taslp-no-balance/asr_epoch_1_step_4000/model.pt
